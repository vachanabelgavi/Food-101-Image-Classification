{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Deep Learning Assignment\n\n1. Loading the input data\n2. Import Libraries\n3. Setting a path for input directory\n4. Create input data frame\n5. Train and Test split\n6. Create Train and Test generators\n7. Models\n   1. Model - Base Model\n   2. Model - Network Architecture\n   3. Model - Activation Fuction\n   4. Model - Gradient Estimation\n   5. Model - Cost Function\n   6. Model - Network Initialization\n   7. Model - Epochs\n   8. Model - Best Model (All Integrated)\n   9. Model - MobileNetV2\n8. Conclusion\n9. Citation\n10. License","metadata":{}},{"cell_type":"markdown","source":"## Understand dataset structure and files\n\n* The dataset being used is [Food 101](https://www.kaggle.com/kmader/food41)\n* This dataset has 101000 images in total. It's a food dataset with 101 categories(multiclass)\n* Each type of food has 750 training samples and 250 test samples\n* Note found on the webpage of the dataset :  \n  * On purpose, the training images were not cleaned, and thus still contain some amount of noise. This comes mostly in the form of intense colors and sometimes wrong labels. All images were rescaled to have a maximum side length of 512 pixels.\n  * The entire dataset is 6GB in size","metadata":{}},{"cell_type":"markdown","source":"## 1. Load the Dataset","metadata":{}},{"cell_type":"markdown","source":"**images** folder contains 101 folders with 1000 images each.<br>\nEach folder contains images of a specific food class.\n\n**meta** folder contains the text files - train.txt and test.txt  \n**train.txt** contains the list of images that belong to training set  \n**test.txt** contains the list of images that belong to test set  \n**classes.txt** contains the list of all classes of food","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:12:20.268130Z","iopub.execute_input":"2021-12-12T03:12:20.268417Z","iopub.status.idle":"2021-12-12T03:12:51.166519Z","shell.execute_reply.started":"2021-12-12T03:12:20.268386Z","shell.execute_reply":"2021-12-12T03:12:51.165710Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## 2. Import Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport os.path\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:15:55.577285Z","iopub.execute_input":"2021-12-12T03:15:55.577738Z","iopub.status.idle":"2021-12-12T03:16:00.391506Z","shell.execute_reply.started":"2021-12-12T03:15:55.577697Z","shell.execute_reply":"2021-12-12T03:16:00.390768Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## 3. Setting path for the input directory","metadata":{}},{"cell_type":"code","source":"image_dir = Path('../input/food41/images')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:16:00.392929Z","iopub.execute_input":"2021-12-12T03:16:00.393180Z","iopub.status.idle":"2021-12-12T03:16:00.398245Z","shell.execute_reply.started":"2021-12-12T03:16:00.393147Z","shell.execute_reply":"2021-12-12T03:16:00.397590Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## 4. Creating File DataFrame\n\nWe are setting the respective paths and labels.","metadata":{}},{"cell_type":"code","source":"filepaths = list(image_dir.glob(r'**/*.jpg'))\nlabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n\nfilepaths = pd.Series(filepaths, name='Filepath').astype(str)\nlabels = pd.Series(labels, name='Label')\n\nimages = pd.concat([filepaths, labels], axis=1)\n\ncategory_samples = []\nfor category in images['Label'].unique():\n    category_slice = images.query(\"Label == @category\")\n    category_samples.append(category_slice.sample(100, random_state=1))\nimage_df = pd.concat(category_samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:16:00.426147Z","iopub.execute_input":"2021-12-12T03:16:00.426454Z","iopub.status.idle":"2021-12-12T03:16:02.597544Z","shell.execute_reply.started":"2021-12-12T03:16:00.426424Z","shell.execute_reply":"2021-12-12T03:16:02.596825Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"image_df","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:16:06.439981Z","iopub.execute_input":"2021-12-12T03:16:06.440231Z","iopub.status.idle":"2021-12-12T03:16:06.467060Z","shell.execute_reply.started":"2021-12-12T03:16:06.440201Z","shell.execute_reply":"2021-12-12T03:16:06.464802Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"image_df['Label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:16:08.845475Z","iopub.execute_input":"2021-12-12T03:16:08.846038Z","iopub.status.idle":"2021-12-12T03:16:08.855487Z","shell.execute_reply.started":"2021-12-12T03:16:08.845999Z","shell.execute_reply":"2021-12-12T03:16:08.854788Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## 5. Train-Test Split","metadata":{}},{"cell_type":"code","source":"train_df, test_df = train_test_split(image_df, train_size=0.7, shuffle=True, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:16:11.657140Z","iopub.execute_input":"2021-12-12T03:16:11.657395Z","iopub.status.idle":"2021-12-12T03:16:11.664760Z","shell.execute_reply.started":"2021-12-12T03:16:11.657367Z","shell.execute_reply":"2021-12-12T03:16:11.663883Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## 6. Creating Generators\n\n\n","metadata":{}},{"cell_type":"markdown","source":"This is where we normalise the data. We mention the size, width and all other parameters such that the images can be flipped, zoom, and more to be recognised in a way that is similar to the rest.","metadata":{}},{"cell_type":"code","source":"train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    rotation_range=30,\n   width_shift_range=0.1,\n   height_shift_range=0.1,\n   rescale=1./255.,\n   shear_range=0.2,\n   zoom_range=0.2,\n   horizontal_flip=True,\n   fill_mode='nearest',\n    validation_split=0.2\n)\n\ntest_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:16:13.461173Z","iopub.execute_input":"2021-12-12T03:16:13.461424Z","iopub.status.idle":"2021-12-12T03:16:14.273122Z","shell.execute_reply.started":"2021-12-12T03:16:13.461396Z","shell.execute_reply":"2021-12-12T03:16:14.272254Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Takes data & label arrays, generates batches of augmented data. Input data. Numpy array of rank 4 or a tuple. If tuple, the first element should contain the images and the second element another numpy array or a list of numpy arrays that gets passed to the output without any modifications.","metadata":{}},{"cell_type":"code","source":"train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n    validation_split=0.2\n)\n\ntest_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:16:15.318439Z","iopub.execute_input":"2021-12-12T03:16:15.318715Z","iopub.status.idle":"2021-12-12T03:16:15.328572Z","shell.execute_reply.started":"2021-12-12T03:16:15.318685Z","shell.execute_reply":"2021-12-12T03:16:15.323135Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Below, we are splitting the dataset into train and test by specifying the target size. We are also specifying other parameters like categorical since it is a classification dataset. The train, test and validation sets are used in further steps for our accuracy.\nBatch size is how many images are taken in a batch.","metadata":{}},{"cell_type":"code","source":"train_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(128, 128),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=8,\n    shuffle=True,\n    seed=42,\n    subset='training'\n)\n\nval_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(128, 128),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=8,\n    shuffle=True,\n    seed=42,\n    subset='validation'\n)\n\ntest_images = test_generator.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(128, 128),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=8,\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:16:17.115863Z","iopub.execute_input":"2021-12-12T03:16:17.116668Z","iopub.status.idle":"2021-12-12T03:16:20.507867Z","shell.execute_reply.started":"2021-12-12T03:16:17.116623Z","shell.execute_reply":"2021-12-12T03:16:20.506633Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## 7. Create Models","metadata":{}},{"cell_type":"markdown","source":"### 1. Model - The base model","metadata":{}},{"cell_type":"markdown","source":"Neural network layer gives output where it scales the value between layers. Below RelU is already in use. Also we are using sequential for sequence layers. Conv2D is used for image classification. We can see a list of layers below, with sizes starting from 1024 and going in a decending manner. The more the number of layers, the more information can be extracted by the model from the dataset. input shape also mentions the shapes which are consequences of the model's configuration. Shapes are tuples representing how many elements an array or tensor has in each dimension.\n\nThe model we are using first is a ADMN. The default network architecture here is random normal. Weights here are gaussian distributions. The loss is the cross entropy loss which has to decrease for us to get a good accuracy.","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Activation\n\nfrom keras.models import Sequential\n\n#add model layers\nmodel = Sequential()\nmodel.add(Conv2D(1024, kernel_size=3, activation= 'relu', input_shape=(128,128, 3)))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(512, kernel_size=3, activation= 'relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(256, kernel_size=3, activation= 'relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(256, kernel_size=3, activation= 'relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(256, kernel_size=3, activation= 'relu'))\nmodel.add(Flatten())\nmodel.add(Dense(101, activation='softmax'))\n          \nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=100\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:55:45.558196Z","iopub.execute_input":"2021-12-11T15:55:45.558529Z","iopub.status.idle":"2021-12-11T17:39:55.657386Z","shell.execute_reply.started":"2021-12-11T15:55:45.558492Z","shell.execute_reply":"2021-12-11T17:39:55.656404Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T21:36:41.778682Z","iopub.execute_input":"2021-12-11T21:36:41.779003Z","iopub.status.idle":"2021-12-11T21:36:42.342996Z","shell.execute_reply.started":"2021-12-11T21:36:41.778968Z","shell.execute_reply":"2021-12-11T21:36:42.342371Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### 2. Model - Network Arcihtecture","metadata":{}},{"cell_type":"markdown","source":"In our second model we are taking a reduced layer number, and sizes respectively.We are making use of sequential, Maxpooling and Dense. Dense is a single vector layer. Max pooling is done to in part to help over-fitting by providing an abstracted form of the representation. As well, it reduces the computational cost by reducing the number of parameters to learn and provides basic translation invariance to the internal representation.","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\nfrom keras.models import Sequential\n#add model layers\nmodel = Sequential()\nmodel.add(Conv2D(102, kernel_size=3, activation= 'relu', input_shape=(128,128, 3)))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(512, kernel_size=3, activation= 'relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(256, kernel_size=3, activation= 'relu'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Conv2D(256, kernel_size=3, activation= 'relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(128, kernel_size=3, activation= 'relu'))\nmodel.add(Flatten())\nmodel.add(Dense(101, activation='softmax'))\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=100\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:58:04.530823Z","iopub.execute_input":"2021-12-11T14:58:04.531089Z","iopub.status.idle":"2021-12-11T15:55:45.556504Z","shell.execute_reply.started":"2021-12-11T14:58:04.531060Z","shell.execute_reply":"2021-12-11T15:55:45.555817Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### 3. Model - Activation Function","metadata":{}},{"cell_type":"markdown","source":"Here, we have tweaked the values using flatten which converges the dataset such as to read it better. Rest has been kept the same for checking accuracy. We can see it increase.","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Activation\n\nfrom keras.models import Sequential\n\n#add model layers\nmodel = Sequential()\nmodel.add(Conv2D(1024, kernel_size=3, activation= 'elu', input_shape=(128,128, 3)))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(512, kernel_size=3, activation= 'elu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(256, kernel_size=3, activation= 'elu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(256, kernel_size=3, activation= 'elu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(256, kernel_size=3, activation= 'elu'))\nmodel.add(Flatten())\nmodel.add(Dense(101, activation='softmax'))\n          \nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=100\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T19:27:54.672890Z","iopub.execute_input":"2021-12-11T19:27:54.673152Z","iopub.status.idle":"2021-12-11T21:21:52.241653Z","shell.execute_reply.started":"2021-12-11T19:27:54.673121Z","shell.execute_reply":"2021-12-11T21:21:52.240882Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### 4. Model - Gradient Estimation","metadata":{}},{"cell_type":"markdown","source":"Here, we have changed the model to SGD.","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Activation\n\nfrom keras.models import Sequential\n\n#add model layers\nmodel = Sequential()\nmodel.add(Conv2D(1024, kernel_size=3, activation= 'relu', input_shape=(128,128, 3)))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(512, kernel_size=3, activation= 'relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(256, kernel_size=3, activation= 'relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(256, kernel_size=3, activation= 'relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(256, kernel_size=3, activation= 'relu'))\nmodel.add(Flatten())\nmodel.add(Dense(101, activation='softmax'))\n\nmodel.compile(\n    optimizer='sgd',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=100\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T22:22:29.745597Z","iopub.execute_input":"2021-12-11T22:22:29.745893Z","iopub.status.idle":"2021-12-12T00:08:01.845119Z","shell.execute_reply.started":"2021-12-11T22:22:29.745862Z","shell.execute_reply":"2021-12-12T00:08:01.844336Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:08:01.846769Z","iopub.execute_input":"2021-12-12T00:08:01.847008Z","iopub.status.idle":"2021-12-12T00:08:02.239602Z","shell.execute_reply.started":"2021-12-12T00:08:01.846968Z","shell.execute_reply":"2021-12-12T00:08:02.238941Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### 5. Model - Cost Function","metadata":{}},{"cell_type":"markdown","source":"Below we have made use of loss function kl_divergence keeping the rest same for checking if accuracy is better.","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Activation\n\nfrom keras.models import Sequential\n\n#add model layers\nmodel = Sequential()\nmodel.add(Conv2D(1024, kernel_size=3, activation= 'relu', input_shape=(128,128, 3)))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(512, kernel_size=3, activation= 'relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(256, kernel_size=3, activation= 'relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(256, kernel_size=3, activation= 'relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(256, kernel_size=3, activation= 'relu'))\nmodel.add(Flatten())\nmodel.add(Dense(101, activation='softmax'))\n          \nmodel.compile(\n    optimizer='adam',\n    loss='kl_divergence',\n    metrics=['accuracy']\n)\n\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=100\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:46:36.377370Z","iopub.execute_input":"2021-12-12T00:46:36.377627Z","iopub.status.idle":"2021-12-12T02:30:20.989951Z","shell.execute_reply.started":"2021-12-12T00:46:36.377599Z","shell.execute_reply":"2021-12-12T02:30:20.989157Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T02:30:20.991594Z","iopub.execute_input":"2021-12-12T02:30:20.991850Z","iopub.status.idle":"2021-12-12T02:30:21.368576Z","shell.execute_reply.started":"2021-12-12T02:30:20.991816Z","shell.execute_reply":"2021-12-12T02:30:21.367926Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### 5. Model - Network Initialization ","metadata":{}},{"cell_type":"markdown","source":"Below, we have used Glorot which is different network initialization when compared with random normal. One common initialization scheme for deep NNs is called Glorot (also known as Xavier) Initialization. The idea is to initialize each weight with a small Gaussian value with mean = 0.0 and variance based on the fan-in and fan-out of the weight.","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\nfrom keras.models import Sequential\n#add model layers\nmodel = Sequential()\nmodel.add(Conv2D(102, kernel_size=3, activation= 'relu', input_shape=(128,128, 3)))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(512, kernel_size=3, activation= 'relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(256, kernel_size=3, activation= 'relu'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Conv2D(256, kernel_size=3, activation= 'relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(128, kernel_size=3, activation= 'relu'))\nmodel.add(Flatten())\nmodel.add(Dense(101,kernel_initializer='glorot_uniform', activation='softmax'))\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=100\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T02:42:20.091007Z","iopub.status.idle":"2021-12-12T02:42:20.091662Z","shell.execute_reply.started":"2021-12-12T02:42:20.091428Z","shell.execute_reply":"2021-12-12T02:42:20.091451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7. Model - EPOCHS","metadata":{}},{"cell_type":"markdown","source":"Here, we are changing the number of epochs to 50 and check how well the model performs in these 50 epochs.","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\nfrom keras.models import Sequential\n#add model layers\nmodel = Sequential()\nmodel.add(Conv2D(102, kernel_size=3, activation= 'relu', input_shape=(128,128, 3)))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(512, kernel_size=3, activation= 'relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(256, kernel_size=3, activation= 'relu'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Conv2D(256, kernel_size=3, activation= 'relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(128, kernel_size=3, activation= 'relu'))\nmodel.add(Flatten())\nmodel.add(Dense(101, activation='softmax'))\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=50\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 8. Model - Integrated","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\nfrom keras.models import Sequential\n#add model layers\nmodel = Sequential()\nmodel.add(Conv2D(102, kernel_size=3, activation= 'elu', input_shape=(128,128, 3)))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(512, kernel_size=3, activation= 'elu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(256, kernel_size=3, activation= 'elu'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Conv2D(256, kernel_size=3, activation= 'elu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(128, kernel_size=3, activation= 'elu'))\nmodel.add(Flatten())\nmodel.add(Dense(101,kernel_initializer='glorot_uniform', activation='softmax'))\n\nmodel.compile(\n    optimizer='sgd',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=100\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 9. Model - Pre-trained  model (MobileNetV2)","metadata":{}},{"cell_type":"code","source":"pretrained_model = tf.keras.applications.MobileNetV2(\n    input_shape=(128, 128, 3),\n    include_top=False,\n    weights='imagenet',\n    pooling='avg'\n)\n\npretrained_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:16:34.791613Z","iopub.execute_input":"2021-12-12T03:16:34.792270Z","iopub.status.idle":"2021-12-12T03:16:38.433817Z","shell.execute_reply.started":"2021-12-12T03:16:34.792231Z","shell.execute_reply":"2021-12-12T03:16:38.432568Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"inputs = pretrained_model.input\n\nx = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\n\noutputs = tf.keras.layers.Dense(101, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs, outputs)\n\n\nprint(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Training the MobileNetV2 model","metadata":{}},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=100,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:16:45.486775Z","iopub.execute_input":"2021-12-12T03:16:45.487437Z","iopub.status.idle":"2021-12-12T03:20:08.775372Z","shell.execute_reply.started":"2021-12-12T03:16:45.487382Z","shell.execute_reply":"2021-12-12T03:20:08.774432Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:20:08.777154Z","iopub.execute_input":"2021-12-12T03:20:08.777493Z","iopub.status.idle":"2021-12-12T03:20:09.181938Z","shell.execute_reply.started":"2021-12-12T03:20:08.777452Z","shell.execute_reply":"2021-12-12T03:20:09.181255Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### 9.1 Changed Activation Function","metadata":{}},{"cell_type":"code","source":"inputs = pretrained_model.input\n\nx = tf.keras.layers.Dense(128, activation='softmax')(pretrained_model.output)\nx = tf.keras.layers.Dense(128, activation='softmax')(x)\n\noutputs = tf.keras.layers.Dense(101, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs, outputs)\n\n\nprint(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=100,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:20:09.289823Z","iopub.execute_input":"2021-12-12T03:20:09.290022Z","iopub.status.idle":"2021-12-12T03:29:04.367435Z","shell.execute_reply.started":"2021-12-12T03:20:09.289998Z","shell.execute_reply":"2021-12-12T03:29:04.366676Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:29:04.369191Z","iopub.execute_input":"2021-12-12T03:29:04.369442Z","iopub.status.idle":"2021-12-12T03:29:04.748336Z","shell.execute_reply.started":"2021-12-12T03:29:04.369409Z","shell.execute_reply":"2021-12-12T03:29:04.747690Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### 9.2 Changed Optimizer","metadata":{}},{"cell_type":"code","source":"inputs = pretrained_model.input\n\nx = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\n\noutputs = tf.keras.layers.Dense(101, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs, outputs)\n\n\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:25:54.613250Z","iopub.execute_input":"2021-12-12T04:25:54.613487Z","iopub.status.idle":"2021-12-12T04:25:54.716062Z","shell.execute_reply.started":"2021-12-12T04:25:54.613451Z","shell.execute_reply":"2021-12-12T04:25:54.715237Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer='sgd',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=100,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:29:55.558858Z","iopub.execute_input":"2021-12-12T03:29:55.559118Z","iopub.status.idle":"2021-12-12T03:33:50.259015Z","shell.execute_reply.started":"2021-12-12T03:29:55.559089Z","shell.execute_reply":"2021-12-12T03:33:50.258123Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:33:50.260958Z","iopub.execute_input":"2021-12-12T03:33:50.261238Z","iopub.status.idle":"2021-12-12T03:33:58.706071Z","shell.execute_reply.started":"2021-12-12T03:33:50.261208Z","shell.execute_reply":"2021-12-12T03:33:58.705402Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### 9.3 Changed Cost Function","metadata":{}},{"cell_type":"code","source":"inputs = pretrained_model.input\n\nx = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\n\noutputs = tf.keras.layers.Dense(101, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs, outputs)\n\n\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:25:54.717161Z","iopub.execute_input":"2021-12-12T04:25:54.717430Z","iopub.status.idle":"2021-12-12T04:25:54.825149Z","shell.execute_reply.started":"2021-12-12T04:25:54.717381Z","shell.execute_reply":"2021-12-12T04:25:54.824472Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss='kl_divergence',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=100,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:52:17.492857Z","iopub.execute_input":"2021-12-12T03:52:17.493367Z","iopub.status.idle":"2021-12-12T03:55:06.375025Z","shell.execute_reply.started":"2021-12-12T03:52:17.493327Z","shell.execute_reply":"2021-12-12T03:55:06.374224Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:55:06.376844Z","iopub.execute_input":"2021-12-12T03:55:06.377120Z","iopub.status.idle":"2021-12-12T03:55:14.742095Z","shell.execute_reply.started":"2021-12-12T03:55:06.377083Z","shell.execute_reply":"2021-12-12T03:55:14.741356Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"### 9.4 Adding Network Initializer","metadata":{}},{"cell_type":"code","source":"inputs = pretrained_model.input\n\nx = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\nx = tf.keras.layers.Dense(128, kernel_initializer='glorot_uniform', activation='relu')(x)\n\noutputs = tf.keras.layers.Dense(101, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs, outputs)\n\n\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:55:14.743628Z","iopub.execute_input":"2021-12-12T03:55:14.744107Z","iopub.status.idle":"2021-12-12T03:55:14.848251Z","shell.execute_reply.started":"2021-12-12T03:55:14.744068Z","shell.execute_reply":"2021-12-12T03:55:14.847573Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=100,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:55:14.850168Z","iopub.execute_input":"2021-12-12T03:55:14.850414Z","iopub.status.idle":"2021-12-12T03:58:02.008303Z","shell.execute_reply.started":"2021-12-12T03:55:14.850377Z","shell.execute_reply":"2021-12-12T03:58:02.007607Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:58:02.009902Z","iopub.execute_input":"2021-12-12T03:58:02.010196Z","iopub.status.idle":"2021-12-12T03:58:02.422101Z","shell.execute_reply.started":"2021-12-12T03:58:02.010161Z","shell.execute_reply":"2021-12-12T03:58:02.421375Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"### 9.5 Change in Epochs","metadata":{}},{"cell_type":"code","source":"inputs = pretrained_model.input\n\nx = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\n\noutputs = tf.keras.layers.Dense(101, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs, outputs)\n\n\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:25:54.511089Z","iopub.execute_input":"2021-12-12T04:25:54.511334Z","iopub.status.idle":"2021-12-12T04:25:54.612308Z","shell.execute_reply.started":"2021-12-12T04:25:54.511301Z","shell.execute_reply":"2021-12-12T04:25:54.611692Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=50\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:58:02.526335Z","iopub.execute_input":"2021-12-12T03:58:02.526579Z","iopub.status.idle":"2021-12-12T04:25:54.118599Z","shell.execute_reply.started":"2021-12-12T03:58:02.526530Z","shell.execute_reply":"2021-12-12T04:25:54.117896Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:25:54.120287Z","iopub.execute_input":"2021-12-12T04:25:54.120538Z","iopub.status.idle":"2021-12-12T04:25:54.508865Z","shell.execute_reply.started":"2021-12-12T04:25:54.120503Z","shell.execute_reply":"2021-12-12T04:25:54.508188Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"## 8.  Conclusion","metadata":{}},{"cell_type":"markdown","source":"In conclusion, we started off with a basic model and changed and tuned parameters and trained with separate models with each change. In some cases, the accuracy increased and in some cases it did not. The MobileNetV2 performed better than the basic model used. When changed the parameters of the basic model and integrated, it gave an accuracy of 96%.","metadata":{}},{"cell_type":"markdown","source":"## 9. Citation\n\n* [KLDivergence](https://www.tensorflow.org/api_docs/python/tf/keras/losses/KLDivergence)\n* [Deep Lizard Keras Tutorial](https://www.youtube.com/watch?v=stWU37L91Yc&list=PLZbbT5o_s2xrfNyHZsM6ufI0iZENK9xgG&index=20)\n* [Display Deep Learning Model Training in Keras](https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/)\n* [Kaggle](https://www.kaggle.com/illukthegreat/starter-food-images)\n* [Keras Starter](https://github.com/rileykwok/Food-Classification/blob/master/Food-101%20Challenge.ipynb)","metadata":{}},{"cell_type":"markdown","source":"## 10. License\n\nCopyright [2021] [Vachana Satish Belgavi, Akshata Nanjappa]\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","metadata":{}}]}