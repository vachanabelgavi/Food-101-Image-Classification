{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:53:12.078245Z","iopub.execute_input":"2021-12-12T00:53:12.078864Z","iopub.status.idle":"2021-12-12T00:53:49.759071Z","shell.execute_reply.started":"2021-12-12T00:53:12.078772Z","shell.execute_reply":"2021-12-12T00:53:49.758304Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport matplotlib.image as img\n%matplotlib inline\nimport numpy as np\nfrom collections import defaultdict\nimport collections\nfrom shutil import copy\nfrom shutil import copytree, rmtree\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport random\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow import keras\nfrom tensorflow.keras import models\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:54:24.148769Z","iopub.execute_input":"2021-12-12T00:54:24.149034Z","iopub.status.idle":"2021-12-12T00:54:30.243605Z","shell.execute_reply.started":"2021-12-12T00:54:24.149006Z","shell.execute_reply":"2021-12-12T00:54:30.242559Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Visualize the image dataset","metadata":{}},{"cell_type":"code","source":"# Visualize the data, showing one image per class from 101 classes\nrows = 17\ncols = 6\nfig, ax = plt.subplots(rows, cols, figsize=(25,25))\n\n# Adding  y=1.05, fontsize=24 helped me fix the suptitle overlapping with axes issue\nfig.suptitle(\"Showing one random image from each class\", y=1.05, fontsize=24) \ndata_dir = \"../input/food41/images\"\nfoods_sorted = sorted(os.listdir(data_dir))\nfood_id = 0\nfor i in range(rows):\n    for j in range(cols):\n        try:\n            food_selected = foods_sorted[food_id] \n            food_id += 1\n        except:\n            break\n        \n        food_selected_images = os.listdir(os.path.join(data_dir,food_selected)) # returns the list of all files present in each food category\n        food_selected_random = np.random.choice(food_selected_images) # picks one food item from the list as choice, takes a list and returns one random item\n        img = plt.imread(os.path.join(data_dir,food_selected, food_selected_random))\n        ax[i][j].imshow(img)\n        ax[i][j].set_title(food_selected, pad = 10)\n    \nplt.setp(ax, xticks=[],yticks=[])\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:54:30.245466Z","iopub.execute_input":"2021-12-12T00:54:30.245898Z","iopub.status.idle":"2021-12-12T00:54:42.029573Z","shell.execute_reply.started":"2021-12-12T00:54:30.245796Z","shell.execute_reply":"2021-12-12T00:54:42.028583Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Split the image data into train and test using train.txt and test.txt","metadata":{}},{"cell_type":"code","source":"from collections import defaultdict\nimport shutil\n\n# Helper method to split dataset into train and test folders\ndef prepare_data(filepath, src, dest):\n    classes_images = defaultdict(list)\n    with open(filepath, 'r') as txt:\n        paths = [read.strip() for read in txt.readlines()]\n        for p in paths:\n            food = p.split('/')\n            classes_images[food[0]].append(food[1] + '.jpg')\n\n    for food in classes_images.keys():\n        print(\"\\nCopying images into \",food)\n        \n        if not os.path.exists(os.path.join(dest,food)):\n            os.makedirs(os.path.join(dest,food))\n            \n        for i in classes_images[food]:\n            shutil.copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n    print(\"Copying Done!\")","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:54:51.077512Z","iopub.execute_input":"2021-12-12T00:54:51.078058Z","iopub.status.idle":"2021-12-12T00:54:51.087242Z","shell.execute_reply.started":"2021-12-12T00:54:51.078021Z","shell.execute_reply":"2021-12-12T00:54:51.086092Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Prepare train dataset by copying images from food-101/images to food-101/train using the file train.txt\nprint(\"Creating train data...\")\nprepare_data('../input/food41/meta/meta/train.txt', '../input/food41/images', './train')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:54:54.534696Z","iopub.execute_input":"2021-12-12T00:54:54.535732Z","iopub.status.idle":"2021-12-12T01:03:18.694605Z","shell.execute_reply.started":"2021-12-12T00:54:54.535683Z","shell.execute_reply":"2021-12-12T01:03:18.693537Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Check how many files are in the train folder\nprint(\"Total number of samples in train folder\")\n!find train -type d -or -type f -printf '.' | wc -c","metadata":{"execution":{"iopub.status.busy":"2021-12-12T01:03:18.696733Z","iopub.execute_input":"2021-12-12T01:03:18.697302Z","iopub.status.idle":"2021-12-12T01:03:19.524275Z","shell.execute_reply.started":"2021-12-12T01:03:18.697252Z","shell.execute_reply":"2021-12-12T01:03:19.523192Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Prepare test data by copying images from food-101/images to food-101/test using the file test.txt\nprint(\"Creating test data...\")\nprepare_data('../input/food41/meta/meta/test.txt', '../input/food41/images', './test')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T01:03:19.527112Z","iopub.execute_input":"2021-12-12T01:03:19.528565Z","iopub.status.idle":"2021-12-12T01:06:07.753198Z","shell.execute_reply.started":"2021-12-12T01:03:19.528509Z","shell.execute_reply":"2021-12-12T01:06:07.752297Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Check how many files are in the test folder\nprint(\"Total number of samples in test folder\")\n!find test -type d -or -type f -printf '.' | wc -c","metadata":{"execution":{"iopub.status.busy":"2021-12-12T01:06:07.755609Z","iopub.execute_input":"2021-12-12T01:06:07.756566Z","iopub.status.idle":"2021-12-12T01:06:08.523025Z","shell.execute_reply.started":"2021-12-12T01:06:07.756516Z","shell.execute_reply":"2021-12-12T01:06:08.521962Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"**Create a subset of data with few classes(3) - train_mini and test_mini for experimenting\nWe now have train and test data ready.**\n* But to experiment and try different architectures, working on the whole data with 101 classes takes a lot of time and computation\n* To proceed with further experiments, I am creating train_min and test_mini, limiting the dataset to 3 classes\n* Since the original problem is multiclass classification which makes key aspects of architectural decisions different from that of binary classification, choosing 3 classes is a good start instead of 2","metadata":{}},{"cell_type":"code","source":"import shutil\n\n# Helper method to create train_mini and test_mini data samples\ndef dataset_mini(food_list, src, dest):\n    if os.path.exists(dest):\n        shutil.rmtree(dest) # removing dataset_mini(if it already exists) folders so that we will have only the classes that we want\n    os.makedirs(dest)\n    for food_item in food_list :\n        print(\"Copying images into\",food_item)\n        shutil.copytree(os.path.join(src,food_item), os.path.join(dest,food_item))","metadata":{"execution":{"iopub.status.busy":"2021-12-12T01:06:16.081903Z","iopub.execute_input":"2021-12-12T01:06:16.082899Z","iopub.status.idle":"2021-12-12T01:06:16.091231Z","shell.execute_reply.started":"2021-12-12T01:06:16.082844Z","shell.execute_reply":"2021-12-12T01:06:16.089878Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# picking 3 food items and generating separate data folders for the same\nfood_list = ['apple_pie','pizza','omelette']\nsrc_train = './train'\ndest_train = './train_mini'\nsrc_test = './test'\ndest_test = './test_mini'","metadata":{"execution":{"iopub.status.busy":"2021-12-12T01:06:19.597529Z","iopub.execute_input":"2021-12-12T01:06:19.598109Z","iopub.status.idle":"2021-12-12T01:06:19.603959Z","shell.execute_reply.started":"2021-12-12T01:06:19.598063Z","shell.execute_reply":"2021-12-12T01:06:19.602501Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"**Creating mini datasets of train with only three classes**","metadata":{}},{"cell_type":"code","source":"print(\"Creating train data folder with new classes\")\ndataset_mini(food_list, src_train, dest_train)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T01:06:22.759920Z","iopub.execute_input":"2021-12-12T01:06:22.760738Z","iopub.status.idle":"2021-12-12T01:06:24.125386Z","shell.execute_reply.started":"2021-12-12T01:06:22.760702Z","shell.execute_reply":"2021-12-12T01:06:24.124212Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(\"Total number of samples in train folder\")\n!find train_mini -type d -or -type f -printf '.' | wc -c","metadata":{"execution":{"iopub.status.busy":"2021-12-12T01:06:24.877517Z","iopub.execute_input":"2021-12-12T01:06:24.878059Z","iopub.status.idle":"2021-12-12T01:06:25.631099Z","shell.execute_reply.started":"2021-12-12T01:06:24.878021Z","shell.execute_reply":"2021-12-12T01:06:25.629906Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"**Creating mini datasets of test with only three classes**","metadata":{}},{"cell_type":"code","source":"print(\"Creating test data folder with new classes\")\ndataset_mini(food_list, src_test, dest_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T01:06:28.655339Z","iopub.execute_input":"2021-12-12T01:06:28.655781Z","iopub.status.idle":"2021-12-12T01:06:29.051408Z","shell.execute_reply.started":"2021-12-12T01:06:28.655731Z","shell.execute_reply":"2021-12-12T01:06:29.049747Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(\"Total number of samples in test folder\")\n!find test_mini -type d -or -type f -printf '.' | wc -c","metadata":{"execution":{"iopub.status.busy":"2021-12-12T01:06:31.419356Z","iopub.execute_input":"2021-12-12T01:06:31.419662Z","iopub.status.idle":"2021-12-12T01:06:32.185677Z","shell.execute_reply.started":"2021-12-12T01:06:31.419602Z","shell.execute_reply":"2021-12-12T01:06:32.184365Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Fine tune Inception Pretrained model using Food 101 dataset\n<br>\n* Keras and other Deep Learning libraries provide pretrained models.\n<br>\n* These are deep neural networks with efficient architectures(like VGG,Inception,ResNet) that are already trained on datasets like ImageNet.\n<br>\n* Using these pretrained models, we can use the already learned weights and add few layers on top to finetune the model to our new data.\n<br>\n* This helps in faster convergance and saves time and computation when compared to models trained from scratch.\n<br>\n* We currently have a subset of dataset with 3 classes - samosa, pizza and omelette.\n<br>\n* Use the below code to finetune Inceptionv3 pretrained model.","metadata":{}},{"cell_type":"code","source":"##### K.clear_session()\nn_classes = 3\nimg_width, img_height = 299, 299\ntrain_data_dir = 'train_mini'\nvalidation_data_dir = 'test_mini'\nnb_train_samples = 2250 #75750\nnb_validation_samples = 750 #25250\nbatch_size = 16\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical')\n\n\ninception = InceptionV3(weights='imagenet', include_top=False)\nx = inception.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(128,activation='relu')(x)\nx = Dropout(0.2)(x)\n\npredictions = Dense(3,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n\nmodel = Model(inputs=inception.input, outputs=predictions)\nmodel.compile(optimizer=SGD(learning_rate=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\ncheckpointer = ModelCheckpoint(filepath='/kaggle/working/best_model_3class.hdf5', verbose=1, save_best_only=True)\ncsv_logger = CSVLogger('/kaggle/working/history_3class.log')\n\nhistory = model.fit_generator(train_generator,\n                    steps_per_epoch = nb_train_samples // batch_size,\n                    validation_data=validation_generator,\n                    validation_steps=nb_validation_samples // batch_size,\n                    epochs=30,\n                    verbose=1,\n                    callbacks=[csv_logger, checkpointer])\n\nmodel.save('/kaggle/working/model_trained_3class.hdf5')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T01:07:04.338999Z","iopub.execute_input":"2021-12-12T01:07:04.339358Z","iopub.status.idle":"2021-12-12T01:43:25.048971Z","shell.execute_reply.started":"2021-12-12T01:07:04.339324Z","shell.execute_reply":"2021-12-12T01:43:25.048018Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class_map_3 = train_generator.class_indices\nclass_map_3","metadata":{"execution":{"iopub.status.busy":"2021-12-12T01:43:25.051368Z","iopub.execute_input":"2021-12-12T01:43:25.051677Z","iopub.status.idle":"2021-12-12T01:43:25.059556Z","shell.execute_reply.started":"2021-12-12T01:43:25.051636Z","shell.execute_reply":"2021-12-12T01:43:25.058508Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### Visualize the accuracy and loss plots","metadata":{}},{"cell_type":"code","source":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T01:45:14.221149Z","iopub.execute_input":"2021-12-12T01:45:14.221455Z","iopub.status.idle":"2021-12-12T01:45:14.706577Z","shell.execute_reply.started":"2021-12-12T01:45:14.221422Z","shell.execute_reply":"2021-12-12T01:45:14.705599Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"* **The plots show that the accuracy of the model increased with epochs and the loss has decreased.**<br>\n* **Validation accuracy has been on the higher side than training accuracy for many epochs.**<br>\n* **This could be for several reasons:**<br>\n  * We used a pretrained model trained on ImageNet which contains data from a variety of classes.<br>\n  * Using dropout can lead to a higher validation accuracy.<br>\n","metadata":{}},{"cell_type":"markdown","source":"### Predicting classes for new images from internet using the best trained model","metadata":{}},{"cell_type":"code","source":"%%time\n# Loading the best saved model to make predictions\nK.clear_session()\nmodel_best = load_model('best_model_3class.hdf5',compile = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T01:45:23.193417Z","iopub.execute_input":"2021-12-12T01:45:23.193729Z","iopub.status.idle":"2021-12-12T01:45:26.004348Z","shell.execute_reply.started":"2021-12-12T01:45:23.193695Z","shell.execute_reply":"2021-12-12T01:45:26.003185Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"* **Setting compile=False and clearing the session leads to faster loading of the saved model.<br>**\n* **Withouth the above addiitons, model loading was taking more than a minute!**","metadata":{}},{"cell_type":"markdown","source":"## Evaluate Results","metadata":{}},{"cell_type":"code","source":"# create another generator for all test images in a single batch \nval_datagen = ImageDataGenerator(rescale=1./255)\nval_generator = test_datagen.flow_from_directory(\n        \"./test_mini\",\n        target_size=(299, 299),\n        batch_size=750)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T01:46:51.317665Z","iopub.execute_input":"2021-12-12T01:46:51.317963Z","iopub.status.idle":"2021-12-12T01:46:51.431430Z","shell.execute_reply.started":"2021-12-12T01:46:51.317931Z","shell.execute_reply":"2021-12-12T01:46:51.430450Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nx_test, y_test = val_generator.next()\ny_pred_conf = model.predict(x_test) #return probabilities of each class\ny_pred = np.argmax(y_pred_conf,axis=1)\ny_label = np.argmax(y_test,axis=1)\n\nprint('Accuracy score: {:.1f}%'.format(accuracy_score(y_pred,y_label)*100))","metadata":{"execution":{"iopub.status.busy":"2021-12-12T01:47:39.199072Z","iopub.execute_input":"2021-12-12T01:47:39.199375Z","iopub.status.idle":"2021-12-12T01:47:47.544794Z","shell.execute_reply.started":"2021-12-12T01:47:39.199344Z","shell.execute_reply":"2021-12-12T01:47:47.543349Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## Randomly making prediction on five images","metadata":{}},{"cell_type":"code","source":"r = 4; c = 7\nn=0\nclasstolabel = {'0':'apple_pie','1':'pizza','2':'omelette'}\nfor x in train_generator:\n    fig, axes = plt.subplots(r,c,figsize=(20,12))\n    for i in range(4):\n        for j in range(7):\n            axes[i,j].imshow(x[0][n])\n            label = np.argmax(x[1],axis=1)[n].astype('str')\n            axes[i,j].set_title(classtolabel[label])\n            n+=1    \n    break","metadata":{"execution":{"iopub.status.busy":"2021-12-12T01:59:57.730331Z","iopub.execute_input":"2021-12-12T01:59:57.730650Z","iopub.status.idle":"2021-12-12T02:00:02.263562Z","shell.execute_reply.started":"2021-12-12T01:59:57.730598Z","shell.execute_reply":"2021-12-12T02:00:02.261694Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"ind = np.random.randint(1,len(x_test),5)\nf, ax=plt.subplots(1,5,figsize=(20,10))\nfor i,j in enumerate(ind):\n    ax[i].imshow(x_test[j])\n    ax[i].set_title(\"Pred :{}({:.2f})\\nTrue :{}({:.2f})\".format\n                          (classtolabel[str(y_pred[j])],np.max(y_pred_conf[j]),\n                           classtolabel[str(y_label[j])],y_pred_conf[j][(y_label[j])],fontweight=\"bold\", size=20))","metadata":{"execution":{"iopub.status.busy":"2021-12-12T02:01:03.295820Z","iopub.execute_input":"2021-12-12T02:01:03.296776Z","iopub.status.idle":"2021-12-12T02:01:04.388545Z","shell.execute_reply.started":"2021-12-12T02:01:03.296742Z","shell.execute_reply":"2021-12-12T02:01:04.387595Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"### Changed Activation Of Dense Layer to Softmax","metadata":{}},{"cell_type":"code","source":"##### K.clear_session()\nn_classes = 3\nimg_width, img_height = 299, 299\ntrain_data_dir = 'train_mini'\nvalidation_data_dir = 'test_mini'\nnb_train_samples = 2250 #75750\nnb_validation_samples = 750 #25250\nbatch_size = 16\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical')\n\n\ninception = InceptionV3(weights='imagenet', include_top=False)\nx = inception.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(128,activation='softmax')(x)\nx = Dropout(0.2)(x)\n\npredictions = Dense(3,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n\nmodel = Model(inputs=inception.input, outputs=predictions)\nmodel.compile(optimizer=SGD(learning_rate=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\ncheckpointer = ModelCheckpoint(filepath='/kaggle/working/best_model_3class.hdf5', verbose=1, save_best_only=True)\ncsv_logger = CSVLogger('/kaggle/working/history_3class_softmax.log')\n\nhistory = model.fit_generator(train_generator,\n                    steps_per_epoch = nb_train_samples // batch_size,\n                    validation_data=validation_generator,\n                    validation_steps=nb_validation_samples // batch_size,\n                    epochs=30,\n                    verbose=1,\n                    callbacks=[csv_logger, checkpointer])\n\nmodel.save('/kaggle/working/model_trained_3class.hdf5')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T02:04:31.307651Z","iopub.execute_input":"2021-12-12T02:04:31.308136Z","iopub.status.idle":"2021-12-12T02:41:08.998806Z","shell.execute_reply.started":"2021-12-12T02:04:31.308102Z","shell.execute_reply":"2021-12-12T02:41:08.997544Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T02:41:09.002200Z","iopub.execute_input":"2021-12-12T02:41:09.002552Z","iopub.status.idle":"2021-12-12T02:41:09.477775Z","shell.execute_reply.started":"2021-12-12T02:41:09.002509Z","shell.execute_reply":"2021-12-12T02:41:09.476564Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nx_test, y_test = val_generator.next()\ny_pred_conf = model.predict(x_test) #return probabilities of each class\ny_pred = np.argmax(y_pred_conf,axis=1)\ny_label = np.argmax(y_test,axis=1)\n\nprint('Accuracy score: {:.1f}%'.format(accuracy_score(y_pred,y_label)*100))","metadata":{"execution":{"iopub.status.busy":"2021-12-12T02:45:17.692829Z","iopub.execute_input":"2021-12-12T02:45:17.693331Z","iopub.status.idle":"2021-12-12T02:45:26.881714Z","shell.execute_reply.started":"2021-12-12T02:45:17.693295Z","shell.execute_reply":"2021-12-12T02:45:26.880586Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"### Change in Gradient Estimation","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\n##### K.clear_session()\nn_classes = 3\nimg_width, img_height = 299, 299\ntrain_data_dir = 'train_mini'\nvalidation_data_dir = 'test_mini'\nnb_train_samples = 2250 #75750\nnb_validation_samples = 750 #25250\nbatch_size = 16\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical')\n\n\ninception = InceptionV3(weights='imagenet', include_top=False)\nx = inception.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(128,activation='relu')(x)\nx = Dropout(0.2)(x)\n\npredictions = Dense(3,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n\nmodel = Model(inputs=inception.input, outputs=predictions)\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\ncheckpointer = ModelCheckpoint(filepath='/kaggle/working/best_model_3class.hdf5', verbose=1, save_best_only=True)\ncsv_logger = CSVLogger('/kaggle/working/history_3class.log')\n\nhistory = model.fit_generator(train_generator,\n                    steps_per_epoch = nb_train_samples // batch_size,\n                    validation_data=validation_generator,\n                    validation_steps=nb_validation_samples // batch_size,\n                    epochs=30,\n                    verbose=1,\n                    callbacks=[csv_logger, checkpointer])\n\nmodel.save('/kaggle/working/model_trained_3class.hdf5')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T02:46:44.361283Z","iopub.execute_input":"2021-12-12T02:46:44.361544Z","iopub.status.idle":"2021-12-12T03:22:04.197808Z","shell.execute_reply.started":"2021-12-12T02:46:44.361514Z","shell.execute_reply":"2021-12-12T03:22:04.196703Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:22:04.214924Z","iopub.execute_input":"2021-12-12T03:22:04.223963Z","iopub.status.idle":"2021-12-12T03:22:04.773658Z","shell.execute_reply.started":"2021-12-12T03:22:04.223909Z","shell.execute_reply":"2021-12-12T03:22:04.772614Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nx_test, y_test = val_generator.next()\ny_pred_conf = model.predict(x_test) #return probabilities of each class\ny_pred = np.argmax(y_pred_conf,axis=1)\ny_label = np.argmax(y_test,axis=1)\n\nprint('Accuracy score: {:.1f}%'.format(accuracy_score(y_pred,y_label)*100))","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:22:17.780626Z","iopub.execute_input":"2021-12-12T03:22:17.780971Z","iopub.status.idle":"2021-12-12T03:22:27.079650Z","shell.execute_reply.started":"2021-12-12T03:22:17.780938Z","shell.execute_reply":"2021-12-12T03:22:27.077686Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"### Changing Cost Function","metadata":{}},{"cell_type":"code","source":"##### K.clear_session()\nn_classes = 3\nimg_width, img_height = 299, 299\ntrain_data_dir = 'train_mini'\nvalidation_data_dir = 'test_mini'\nnb_train_samples = 2250 #75750\nnb_validation_samples = 750 #25250\nbatch_size = 16\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical')\n\n\ninception = InceptionV3(weights='imagenet', include_top=False)\nx = inception.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(128,activation='relu')(x)\nx = Dropout(0.2)(x)\n\npredictions = Dense(3,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n\nmodel = Model(inputs=inception.input, outputs=predictions)\nmodel.compile(optimizer=SGD(learning_rate=0.0001, momentum=0.9), loss='kl_divergence', metrics=['accuracy'])\ncheckpointer = ModelCheckpoint(filepath='/kaggle/working/best_model_3class.hdf5', verbose=1, save_best_only=True)\ncsv_logger = CSVLogger('/kaggle/working/history_3class.log')\n\nhistory = model.fit_generator(train_generator,\n                    steps_per_epoch = nb_train_samples // batch_size,\n                    validation_data=validation_generator,\n                    validation_steps=nb_validation_samples // batch_size,\n                    epochs=30,\n                    verbose=1,\n                    callbacks=[csv_logger, checkpointer])\n\nmodel.save('/kaggle/working/model_trained_3class.hdf5')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T03:46:07.585956Z","iopub.execute_input":"2021-12-12T03:46:07.586231Z","iopub.status.idle":"2021-12-12T04:21:40.435779Z","shell.execute_reply.started":"2021-12-12T03:46:07.586200Z","shell.execute_reply":"2021-12-12T04:21:40.434570Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:21:40.443394Z","iopub.execute_input":"2021-12-12T04:21:40.443631Z","iopub.status.idle":"2021-12-12T04:21:40.921844Z","shell.execute_reply.started":"2021-12-12T04:21:40.443605Z","shell.execute_reply":"2021-12-12T04:21:40.920878Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nx_test, y_test = val_generator.next()\ny_pred_conf = model.predict(x_test) #return probabilities of each class\ny_pred = np.argmax(y_pred_conf,axis=1)\ny_label = np.argmax(y_test,axis=1)\n\nprint('Accuracy score: {:.1f}%'.format(accuracy_score(y_pred,y_label)*100))","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:21:40.923457Z","iopub.execute_input":"2021-12-12T04:21:40.923955Z","iopub.status.idle":"2021-12-12T04:21:50.233665Z","shell.execute_reply.started":"2021-12-12T04:21:40.923912Z","shell.execute_reply":"2021-12-12T04:21:50.232319Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}